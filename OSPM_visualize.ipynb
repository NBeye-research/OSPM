{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15c2148f-c1b0-46e0-87f6-2db29e13d5b8",
   "metadata": {},
   "source": [
    "## Masked Autoencoders: Visualization Demo\n",
    "\n",
    "This is a visualization demo of OSPM. No GPU is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffa39c9-ca9b-4da0-90a4-de96bebbf755",
   "metadata": {},
   "source": [
    "### Prepare\n",
    "Check environment. Install packages if in Colab.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eae7403-f458-4f55-a557-4e045bd6f679",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import requests\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "# check whether run in Colab\n",
    "if 'google.colab' in sys.modules:\n",
    "    print('Running in Colab.')\n",
    "    !pip3 install timm==0.4.5  # 0.3.2 does not work in Colab\n",
    "    !git clone https://github.com/facebookresearch/mae.git\n",
    "    sys.path.append('./mae')\n",
    "else:\n",
    "    sys.path.append('..')\n",
    "import models_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7797ef-412a-439f-911e-3be294047629",
   "metadata": {},
   "source": [
    "### Define utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea6ccdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define the utils\n",
    "\n",
    "imagenet_mean = np.array([0.485, 0.456, 0.406])\n",
    "imagenet_std = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "def show_image(image, title=''):\n",
    "    # image is [H, W, 3]\n",
    "    assert image.shape[2] == 3\n",
    "    # plt.figure(dpi=300)\n",
    "    plt.imshow(torch.clip((image * imagenet_std + imagenet_mean) * 255, 0, 255).int())\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.axis('off')\n",
    "    return\n",
    "\n",
    "def prepare_model(chkpt_dir, arch='mae_vit_large_patch16'):\n",
    "    # build model\n",
    "    model = getattr(models_mae, arch)()\n",
    "    # load model\n",
    "    checkpoint = torch.load(chkpt_dir, map_location='cpu')\n",
    "    print(checkpoint.keys())\n",
    "    msg = model.load_state_dict(checkpoint['model'], strict=False)\n",
    "    print(msg)\n",
    "    return model\n",
    "\n",
    "def run_one_image(resize_img, img, model, root_dir, name):\n",
    "    x = torch.tensor(img)\n",
    "\n",
    "    # make it a batch-like\n",
    "    x = x.unsqueeze(dim=0)\n",
    "    x = torch.einsum('nhwc->nchw', x)\n",
    "\n",
    "    # run MAE\n",
    "    loss, y, mask = model(x.float(), mask_ratio=0.85)\n",
    "    y = model.unpatchify(y)\n",
    "    y = torch.einsum('nchw->nhwc', y).detach().cpu()\n",
    "\n",
    "    # visualize the mask\n",
    "    mask = mask.detach()\n",
    "    mask = mask.unsqueeze(-1).repeat(1, 1, model.patch_embed.patch_size[0]**2 *3)  # (N, H*W, p*p*3)\n",
    "    mask = model.unpatchify(mask)  # 1 is removing, 0 is keeping\n",
    "    mask = torch.einsum('nchw->nhwc', mask).detach().cpu()\n",
    "    \n",
    "    x = torch.einsum('nchw->nhwc', x)\n",
    "\n",
    "    # masked image\n",
    "    im_masked = x * (1 - mask)\n",
    "\n",
    "    # MAE reconstruction pasted with visible patches\n",
    "    im_paste = x * (1 - mask) + y * mask\n",
    "\n",
    "    def tranfer_p(image, title=''):\n",
    "        imagenet_mean = np.array([0.485, 0.456, 0.406])\n",
    "        imagenet_std = np.array([0.229, 0.224, 0.225])\n",
    "        # image is [H, W, 3]\n",
    "        assert image.shape[2] == 3\n",
    "        return torch.clip((image * imagenet_std + imagenet_mean) * 255, 0, 255).int()\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 3, dpi=300)\n",
    "    axs[0].imshow(resize_img)\n",
    "    axs[0].set_title('Original', fontsize=6)\n",
    "    axs[0].axis('off')\n",
    "    resize_img.save(root_dir + name + '_resized.tiff') \n",
    "    \n",
    "    mask_img = tranfer_p(im_masked[0])\n",
    "    \n",
    "    axs[1].imshow(tranfer_p(im_masked[0]))\n",
    "    axs[1].set_title('Masked', fontsize=6)\n",
    "    axs[1].axis('off')\n",
    "    mask_image = np.clip(mask_img.detach().cpu().numpy(), 0, 255).astype(np.uint8)\n",
    "    print(type(mask_image))\n",
    "    print(mask_image.shape)\n",
    "    plt.imsave(root_dir + name + '_masked.tiff', mask_image)\n",
    "    reconstructed_img = tranfer_p(im_paste[0])\n",
    "    axs[2].imshow(reconstructed_img)\n",
    "    axs[2].set_title('Reconstructed', fontsize=6)\n",
    "    axs[2].axis('off')\n",
    "    reconstructed_image = np.clip(reconstructed_img.detach().cpu().numpy(), 0, 255).astype(np.uint8)\n",
    "    plt.imsave(root_dir + name + '_reconstructed.tiff', reconstructed_image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad82b2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "chkpt_dir = './pretrain_models/mae_OS_pretrain_ckpt.pth'\n",
    "model_mae = prepare_model(chkpt_dir, 'mae_vit_large_patch16')\n",
    "print('Model loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0502b18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import PIL\n",
    "\n",
    "root_dir = './example_img/'\n",
    "image_name = 'example_oremalignant.jpg'\n",
    "name, _ = os.path.splitext(image_name)\n",
    "\n",
    "img = Image.open(root_dir + image_name)\n",
    "img = img.resize((224, 224),Image.LANCZOS)\n",
    "resize_img = img.resize((512, 512),Image.LANCZOS)\n",
    "img = np.array(img) / 255.\n",
    "\n",
    "assert img.shape == (224, 224, 3)\n",
    "\n",
    "# normalize by ImageNet mean and std\n",
    "img = img - imagenet_mean\n",
    "img = img / imagenet_std\n",
    "\n",
    "torch.manual_seed(11)\n",
    "print('MAE with pixel reconstruction:')\n",
    "run_one_image(resize_img, img, model_mae, root_dir, name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
